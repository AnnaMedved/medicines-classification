{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvkgktk9EUut"
      },
      "source": [
        "Get data from github"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AnnaMedved/medicines-classification.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUFe0VonEv-C",
        "outputId": "d7b1ef1e-b974-4bc4-8135-3083d46aef6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'medicines-classification'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 83 (delta 18), reused 28 (delta 14), pack-reused 51\u001b[K\n",
            "Unpacking objects: 100% (83/83), 97.48 MiB | 8.22 MiB/s, done.\n",
            "Updating files: 100% (29/29), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/medicines-classification/bert_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aByJk_MFA8h",
        "outputId": "bc89ae6a-9f2e-467b-998d-eaa0d342bd68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/medicines-classification/bert_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbiccyZg6-kE",
        "outputId": "e23c9998-570c-4c1d-bf22-957e4b113f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp39-cp39-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.1/804.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp39-cp39-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp39-cp39-manylinux1_x86_64.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==0.22.2 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0rc1, 1.2.0, 1.2.1, 1.2.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scikit-learn==0.22.2\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JasJclP8E3qG"
      },
      "source": [
        "Installing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASlmsIsJE4L2",
        "outputId": "ff72747e-749b-4db8-8902-ff782d7cef6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working in  a:\\Documents\\medicines-classification\\bert_model\n",
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp39-cp39-win_amd64.whl (190.5 MB)\n",
            "     -------------------------------------- 190.5/190.5 MB 2.0 MB/s eta 0:00:00\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp39-cp39-win_amd64.whl (1.2 MB)\n",
            "     ---------------------------------------- 1.2/1.2 MB 3.5 MB/s eta 0:00:00\n",
            "Collecting transformers==4.5.1\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "     ---------------------------------------- 2.1/2.1 MB 2.5 MB/s eta 0:00:00\n",
            "Collecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp39-cp39-win_amd64.whl (8.9 MB)\n",
            "     ---------------------------------------- 8.9/8.9 MB 2.9 MB/s eta 0:00:00\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp39-cp39-win_amd64.whl (13.3 MB)\n",
            "     ---------------------------------------- 13.3/13.3 MB 3.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement scikit-learn==0.22.2 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0rc1, 1.2.0, 1.2.1, 1.2.2)\n",
            "ERROR: No matching distribution found for scikit-learn==0.22.2\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "print('Working in ', os.getcwd())\n",
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwP52Y5YNSWW"
      },
      "source": [
        "## Getting prepared train, valid data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDgGKZmU7t3N"
      },
      "outputs": [],
      "source": [
        "# train_data = pd.read_csv('/content/train.csv')\n",
        "# valid_data = pd.read_csv('/content/valid.csv')\n",
        "# test_data  = pd.read_csv('/content/test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "ZwvxJjfeNSWW",
        "outputId": "983fa350-62b6-486f-fcd6-6b319295b2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bf855c33d81b>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv('data/lemm.csv', error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  ИД правила  Класс  Подуровень   Дата акт.  ИД источника  \\\n",
              "0           0       38039      2           6  2014-12-22          88.0   \n",
              "1           1       38041      2           6  2014-12-22          88.0   \n",
              "2           2       38040      2           6  2019-02-04          88.0   \n",
              "3           3       68429      2           8  2022-11-30          88.0   \n",
              "4           4       68426      2           2  2022-11-30          88.0   \n",
              "\n",
              "                                     Источник  \\\n",
              "0  1б. Инструкция на ЛС (grls.rosminzdrav.ru)   \n",
              "1  1б. Инструкция на ЛС (grls.rosminzdrav.ru)   \n",
              "2  1б. Инструкция на ЛС (grls.rosminzdrav.ru)   \n",
              "3  1б. Инструкция на ЛС (grls.rosminzdrav.ru)   \n",
              "4  1б. Инструкция на ЛС (grls.rosminzdrav.ru)   \n",
              "\n",
              "                                            Левое ДВ  \\\n",
              "0  4-нитро-N-[(1RS)-1-(4-фторфенил)-2-(1-этилпипе...   \n",
              "1  4-нитро-N-[(1RS)-1-(4-фторфенил)-2-(1-этилпипе...   \n",
              "2  4-нитро-N-[(1RS)-1-(4-фторфенил)-2-(1-этилпипе...   \n",
              "3  7-[N-(4-трифторметилбензоил)-гидразинокарбонил...   \n",
              "4  7-[N-(4-трифторметилбензоил)-гидразинокарбонил...   \n",
              "\n",
              "                         Левая ФГ      Правое ДВ  ...  \\\n",
              "0  0020 Антиаритмические средства     Верапамил*  ...   \n",
              "1  0020 Антиаритмические средства      Дигоксин*  ...   \n",
              "2  0020 Антиаритмические средства     Дилтиазем*  ...   \n",
              "3   0030 Противовирусные средства  Аторвастатин*  ...   \n",
              "4   0030 Противовирусные средства     Бупропион*  ...   \n",
              "\n",
              "                               preproccessed_sources  \\\n",
              "0  из за риска развития брадикардии и нарушений п...   \n",
              "1  из за риска развития брадикардии и нарушений п...   \n",
              "2  из за риска развития брадикардии и нарушений п...   \n",
              "3  НИОХ капс Следует с осторожностью назначать од...   \n",
              "4  НИОХ капс Совместно применение Тековиримата с ...   \n",
              "\n",
              "                                  preproccessed_rule  \\\n",
              "0  Из за риска развития брадикардии и нарушений п...   \n",
              "1  Из за риска развития брадикардии и нарушений п...   \n",
              "2  Из за риска развития брадикардии и нарушений п...   \n",
              "3  Следует с осторожностью назначать одновременно...   \n",
              "4  Совместное применение тековиримата активный ме...   \n",
              "\n",
              "                                              prep_1  \\\n",
              "0  из за риска развития брадикардии и нарушений п...   \n",
              "1  из за риска развития брадикардии и нарушений п...   \n",
              "2  из за риска развития брадикардии и нарушений п...   \n",
              "3  ниох капс следует с осторожностью назначать од...   \n",
              "4  ниох капс совместно применение тековиримата с ...   \n",
              "\n",
              "                                              prep_2  \\\n",
              "0  из за риска развития брадикардии и нарушений п...   \n",
              "1  из за риска развития брадикардии и нарушений п...   \n",
              "2  из за риска развития брадикардии и нарушений п...   \n",
              "3  следует с осторожностью назначать одновременно...   \n",
              "4  совместное применение тековиримата активный ме...   \n",
              "\n",
              "                                              text_1  \\\n",
              "0  риск развит брадикард нарушен проводим рекомен...   \n",
              "1  риск развит брадикард нарушен проводим рекомен...   \n",
              "2  риск развит брадикард нарушен проводим рекомен...   \n",
              "3  ниох капс след осторожн назнача одновремен тек...   \n",
              "4  ниох капс совместн применен тековиримат мидазо...   \n",
              "\n",
              "                                              text_2  \\\n",
              "0  риск развит брадикард нарушен проводим рекомен...   \n",
              "1  риск развит брадикард нарушен проводим рекомен...   \n",
              "2  риск развит брадикард нарушен проводим рекомен...   \n",
              "3  след осторожн назнача одновремен тековиримат а...   \n",
              "4  совместн применен тековиримат активн метабол n...   \n",
              "\n",
              "                                           text_sw_1  \\\n",
              "0  риска развития брадикардии нарушений проводимо...   \n",
              "1  риска развития брадикардии нарушений проводимо...   \n",
              "2  риска развития брадикардии нарушений проводимо...   \n",
              "3  ниох капс следует осторожностью назначать одно...   \n",
              "4  ниох капс совместно применение тековиримата ми...   \n",
              "\n",
              "                                           text_sw_2  \\\n",
              "0  риска развития брадикардии нарушений проводимо...   \n",
              "1  риска развития брадикардии нарушений проводимо...   \n",
              "2  риска развития брадикардии нарушений проводимо...   \n",
              "3  следует осторожностью назначать одновременно т...   \n",
              "4  совместное применение тековиримата активный ме...   \n",
              "\n",
              "                                         text_lemm_1  \\\n",
              "0  риск развитие брадикардия нарушение проводимос...   \n",
              "1  риск развитие брадикардия нарушение проводимос...   \n",
              "2  риск развитие брадикардия нарушение проводимос...   \n",
              "3  ниох капс следовать осторожность назначать одн...   \n",
              "4  ниох капс совместно применение тековиримат мид...   \n",
              "\n",
              "                                         text_lemm_2  \n",
              "0  риск развитие брадикардия нарушение проводимос...  \n",
              "1  риск развитие брадикардия нарушение проводимос...  \n",
              "2  риск развитие брадикардия нарушение проводимос...  \n",
              "3  ниох капс следовать осторожность назначать одн...  \n",
              "4  ниох капс совместно применение тековиримат мид...  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2dc9a2c-ea56-4657-9ca1-5747b375e5c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ИД правила</th>\n",
              "      <th>Класс</th>\n",
              "      <th>Подуровень</th>\n",
              "      <th>Дата акт.</th>\n",
              "      <th>ИД источника</th>\n",
              "      <th>Источник</th>\n",
              "      <th>Левое ДВ</th>\n",
              "      <th>Левая ФГ</th>\n",
              "      <th>Правое ДВ</th>\n",
              "      <th>...</th>\n",
              "      <th>preproccessed_sources</th>\n",
              "      <th>preproccessed_rule</th>\n",
              "      <th>prep_1</th>\n",
              "      <th>prep_2</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>text_sw_1</th>\n",
              "      <th>text_sw_2</th>\n",
              "      <th>text_lemm_1</th>\n",
              "      <th>text_lemm_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>38039</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2014-12-22</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1б. Инструкция на ЛС (grls.rosminzdrav.ru)</td>\n",
              "      <td>4-нитро-N-[(1RS)-1-(4-фторфенил)-2-(1-этилпипе...</td>\n",
              "      <td>0020 Антиаритмические средства</td>\n",
              "      <td>Верапамил*</td>\n",
              "      <td>...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>Из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>риск развит брадикард нарушен проводим рекомен...</td>\n",
              "      <td>риск развит брадикард нарушен проводим рекомен...</td>\n",
              "      <td>риска развития брадикардии нарушений проводимо...</td>\n",
              "      <td>риска развития брадикардии нарушений проводимо...</td>\n",
              "      <td>риск развитие брадикардия нарушение проводимос...</td>\n",
              "      <td>риск развитие брадикардия нарушение проводимос...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>38041</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2014-12-22</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1б. Инструкция на ЛС (grls.rosminzdrav.ru)</td>\n",
              "      <td>4-нитро-N-[(1RS)-1-(4-фторфенил)-2-(1-этилпипе...</td>\n",
              "      <td>0020 Антиаритмические средства</td>\n",
              "      <td>Дигоксин*</td>\n",
              "      <td>...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>Из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>риск развит брадикард нарушен проводим рекомен...</td>\n",
              "      <td>риск развит брадикард нарушен проводим рекомен...</td>\n",
              "      <td>риска развития брадикардии нарушений проводимо...</td>\n",
              "      <td>риска развития брадикардии нарушений проводимо...</td>\n",
              "      <td>риск развитие брадикардия нарушение проводимос...</td>\n",
              "      <td>риск развитие брадикардия нарушение проводимос...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>38040</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2019-02-04</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1б. Инструкция на ЛС (grls.rosminzdrav.ru)</td>\n",
              "      <td>4-нитро-N-[(1RS)-1-(4-фторфенил)-2-(1-этилпипе...</td>\n",
              "      <td>0020 Антиаритмические средства</td>\n",
              "      <td>Дилтиазем*</td>\n",
              "      <td>...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>Из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>из за риска развития брадикардии и нарушений п...</td>\n",
              "      <td>риск развит брадикард нарушен проводим рекомен...</td>\n",
              "      <td>риск развит брадикард нарушен проводим рекомен...</td>\n",
              "      <td>риска развития брадикардии нарушений проводимо...</td>\n",
              "      <td>риска развития брадикардии нарушений проводимо...</td>\n",
              "      <td>риск развитие брадикардия нарушение проводимос...</td>\n",
              "      <td>риск развитие брадикардия нарушение проводимос...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>68429</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2022-11-30</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1б. Инструкция на ЛС (grls.rosminzdrav.ru)</td>\n",
              "      <td>7-[N-(4-трифторметилбензоил)-гидразинокарбонил...</td>\n",
              "      <td>0030 Противовирусные средства</td>\n",
              "      <td>Аторвастатин*</td>\n",
              "      <td>...</td>\n",
              "      <td>НИОХ капс Следует с осторожностью назначать од...</td>\n",
              "      <td>Следует с осторожностью назначать одновременно...</td>\n",
              "      <td>ниох капс следует с осторожностью назначать од...</td>\n",
              "      <td>следует с осторожностью назначать одновременно...</td>\n",
              "      <td>ниох капс след осторожн назнача одновремен тек...</td>\n",
              "      <td>след осторожн назнача одновремен тековиримат а...</td>\n",
              "      <td>ниох капс следует осторожностью назначать одно...</td>\n",
              "      <td>следует осторожностью назначать одновременно т...</td>\n",
              "      <td>ниох капс следовать осторожность назначать одн...</td>\n",
              "      <td>ниох капс следовать осторожность назначать одн...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>68426</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-11-30</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1б. Инструкция на ЛС (grls.rosminzdrav.ru)</td>\n",
              "      <td>7-[N-(4-трифторметилбензоил)-гидразинокарбонил...</td>\n",
              "      <td>0030 Противовирусные средства</td>\n",
              "      <td>Бупропион*</td>\n",
              "      <td>...</td>\n",
              "      <td>НИОХ капс Совместно применение Тековиримата с ...</td>\n",
              "      <td>Совместное применение тековиримата активный ме...</td>\n",
              "      <td>ниох капс совместно применение тековиримата с ...</td>\n",
              "      <td>совместное применение тековиримата активный ме...</td>\n",
              "      <td>ниох капс совместн применен тековиримат мидазо...</td>\n",
              "      <td>совместн применен тековиримат активн метабол n...</td>\n",
              "      <td>ниох капс совместно применение тековиримата ми...</td>\n",
              "      <td>совместное применение тековиримата активный ме...</td>\n",
              "      <td>ниох капс совместно применение тековиримат мид...</td>\n",
              "      <td>ниох капс совместно применение тековиримат мид...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2dc9a2c-ea56-4657-9ca1-5747b375e5c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2dc9a2c-ea56-4657-9ca1-5747b375e5c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2dc9a2c-ea56-4657-9ca1-5747b375e5c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data/lemm.csv', error_bad_lines=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jSiGixRy-h2c"
      },
      "outputs": [],
      "source": [
        "from bert_dataset import CustomDataset\n",
        "from bert_classifier import BertClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJtu_4PKFAxU"
      },
      "source": [
        "Initialize BERT classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I7Jqe5mEtrQ",
        "outputId": "aadbc53c-5a88-4e33-9932-a5299bc10267"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6, 8, 2, 4, 5, 7, 3, 1], dtype=int64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Подуровень'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJEhVSxvEtrR",
        "outputId": "1034740a-65a8-4218-e502-2b3663149c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'rubert-tiny'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 86 (delta 1), reused 0 (delta 0), pack-reused 79\u001b[K\n",
            "Unpacking objects: 100% (86/86), 316.43 KiB | 2.09 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 90.92 MiB | 53.66 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/cointegrated/rubert-tiny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFHabt8p_IY7",
        "outputId": "e083c4ae-d15c-4410-9f46-4c1063dcd6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(df['Подуровень'].unique())\n",
        "\n",
        "classifier = BertClassifier(\n",
        "        model_path='rubert-tiny',\n",
        "        tokenizer_path='rubert-tiny',\n",
        "        n_classes=num_classes,\n",
        "        epochs=100,\n",
        "        model_save_path='bert_v2.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dc-F_9vFGb1"
      },
      "source": [
        "Prepare data and helpers for train and evlauation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df['text_lemm_1'] + df['text_lemm_2'])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "VRhpXpwGGVQ0",
        "outputId": "f994d3b6-2899-4ce6-cf87-c2c244690261"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'риск развитие брадикардия нарушение проводимость рекомендоваться введение препарат фон прием бета адреноблокатор блокатор  «  медленный  »  кальциевый канал урежать чсс верапамил дилтиазем дигоксин \\nриск развитие брадикардия нарушение проводимость рекомендоваться введение препарат фон прием бета адреноблокатор блокатор  «  медленный  »  кальциевый канал урежать чсс верапамил дилтиазем дигоксин \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tHZ1wTLPr3p"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X, y = df[['text_lemm_1', 'text_lemm_2']], df['Подуровень']\n",
        "X = df['text_lemm_1'] + df['text_lemm_2']\n",
        "y = df['Подуровень']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wANT6YMNEtrS",
        "outputId": "9fdaa7a6-fd20-4593-fb82-cadacd89fd9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_lemm_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4476</th>\n",
              "      <td>метронидазол миконазол подавлять метаболизм те...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7572</th>\n",
              "      <td>паклитаксел конц д инф паклитаксел метаболизир...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9851</th>\n",
              "      <td>тиопентал фармацевтически несовместимый смешив...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1700</th>\n",
              "      <td>роксера комби амлодипин ингибитор изофермент c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>ариф взаимодействие влияние лс амлодипин ингиб...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9225</th>\n",
              "      <td>neuromuscular blocking agents pancuronium brom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4859</th>\n",
              "      <td>фон метформин возможный внезапный изменение фу...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>сочетать применение диуретика замедлять выведе...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9845</th>\n",
              "      <td>тиопентал фармацевтически несовместимый смешив...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2732</th>\n",
              "      <td>лс пролонгировать интервал qt возможно фармако...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7065 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            text_lemm_1\n",
              "4476  метронидазол миконазол подавлять метаболизм те...\n",
              "7572  паклитаксел конц д инф паклитаксел метаболизир...\n",
              "9851  тиопентал фармацевтически несовместимый смешив...\n",
              "1700  роксера комби амлодипин ингибитор изофермент c...\n",
              "1299  ариф взаимодействие влияние лс амлодипин ингиб...\n",
              "...                                                 ...\n",
              "9225  neuromuscular blocking agents pancuronium brom...\n",
              "4859  фон метформин возможный внезапный изменение фу...\n",
              "3264  сочетать применение диуретика замедлять выведе...\n",
              "9845  тиопентал фармацевтически несовместимый смешив...\n",
              "2732  лс пролонгировать интервал qt возможно фармако...\n",
              "\n",
              "[7065 rows x 1 columns]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4NFjvO6EtrS",
        "outputId": "ab4e7ed1-c756-49db-8aed-a86c74935e58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['метронидазол миконазол подавлять метаболизм терфенадин увеличивать концентрация плазма \\n'],\n",
              "       ['паклитаксел конц д инф паклитаксел метаболизироваться участие изофермент cyp c cyp a поэтому следовать соблюдать осторожность использование паклитаксел фон лечение субстрат например мидазол буспирон фелодипин ловастатин элетриптан силденафил симвастатин триазол репаглинид розиглитазон индуктор например рифампицин карбамазепин фенитоин эфавиренз невирапин ингибитор например эритромицин флуоксетин гемфиброзил кетоконазол ритонавир индинавир нелфинавир данный изофермент \\n'],\n",
              "       ['тиопентал фармацевтически несовместимый смешивать шприц антибиотик амикацин бензилпенициллин цефалоспорин наркотический анальгетик кодеин морфин эфедрин миорелаксант суксаметоний тубокурарин транквилизатор фенотиазин эпинефрино аскорбиновый кислота дипиридамол хлорпромазин кетамин атропин скополамин тубокурарина хлорид \\n'],\n",
              "       ...,\n",
              "       ['сочетать применение диуретика замедлять выведение почка ион литий усиливать токсический эффект литий карбонат \\n'],\n",
              "       ['тиопентал фармацевтически несовместимый смешивать шприц антибиотик амикацин бензилпенициллин цефалоспорин наркотический анальгетик кодеин морфин эфедрин миорелаксант суксаметоний тубокурарин транквилизатор фенотиазин эпинефрино аскорбиновый кислота дипиридамол хлорпромазин кетамин атропин скополамин тубокурарина хлорид \\n'],\n",
              "       ['лс пролонгировать интервал qt возможно фармакологический взаимодействие аддитивный действие пролонгация интервал qt следовать избегать применение пациент получать антиаритмический лс класс ia например хинидин прокаинамид класс iii например амиодарон соталол drugs that prolong qt interval potential pharmacologic interaction additive effect on qt interval prolongation avoid use in patients receiving class ia e g quinidine procainamide or class iii e g amiodarone sotalol antiarrhythmic agents \\n']],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoB7lDv_8AWe",
        "outputId": "b6156c8b-72bb-4175-97c1-6e7a4fa93d92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "a:\\Programs\\Anaconda\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "classifier.preparation(\n",
        "        X_train=X_train.values,\n",
        "        y_train=y_train.values,\n",
        "        X_valid=X_test.values,\n",
        "        y_valid=y_test.values\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUVTfpC5FPsr"
      },
      "source": [
        "Train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Pj_RQTCB9dNJ",
        "outputId": "b55a6c47-ba19-40ab-85c2-a5944e7369ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13252\\2191546134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32ma:\\Documents\\medicines-classification\\bert_model\\bert_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mbest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32ma:\\Documents\\medicines-classification\\bert_model\\bert_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mcorrect_predictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32ma:\\Programs\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32ma:\\Programs\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "classifier.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPqZPcTmFTSd"
      },
      "source": [
        "Check test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1jAxkTkBEMv"
      },
      "outputs": [],
      "source": [
        "texts = list(X_test)\n",
        "labels = list(y_test)\n",
        "\n",
        "predictions = [classifier.predict(t) for t in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llJGj6AJEtrT",
        "outputId": "1c6126ef-d071-46e1-9d2e-c07cd03464bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['text_lemm_1']"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iq7cGj3EtrT",
        "outputId": "9bb6e36a-8315-4e07-e0d9-9fadfb93f66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8, 8]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhJosdy6Bn0o",
        "outputId": "641ec0b6-38fe-4933-e991-f8adb55a42ea"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [3029, 2]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13252\\88316487.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'precision: {precision}, recall: {recall}, f1score: {f1score}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32ma:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32ma:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32ma:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32ma:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3029, 2]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions, average='macro')\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}